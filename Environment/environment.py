class RawEnvironment():
    def __init__(self):
        '''
        To ensure TianShou support, the following values must be added (with gym support)
        action_space: The Space object corresponding to valid actions
        observation_space: The Space object corresponding to valid observations
        reward_range: A tuple corresponding to the min and max possible rewards
        '''
        ''' required attributes:
            num actions: int or None
            action_space: gym.Spaces
            action_shape: tuple of ints
            observation_space = gym.Spaces
            done: boolean
            reward: int
            seed_counter: int
            discrete_actions: boolean
            name: string
        '''
        self.num_actions = None # this must be defined, -1 for continuous. Only needed for primitive actions
        self.name = "ABSTRACT_BASE" # required for an environment 
        self.frame = None # the image generated by the environment
        self.itr = 0 # this is used for saving, and is set externally
        self.recycle = 0 # if we don't want to save all of the data
        self.save_path = "" # save dir also is set using set_save
        self.episode_rewards = deque(maxlen=10) # the episode rewards for the last 10 episodes
        self.reshape = (-1) # the shape of an observation
        self.discrete_actions = True

        # should be set in subclass
        self.action_shape = (1,) # should be set in the environment, (1,) is for discrete action environments
        self.action_space = None
        self.observation_space = None
        self.reward = 0
        self.done = False
        self.seed_counter = -1

        self.environment = environment
        self.frameskip = environment.frameskip
        self.object_names = [] # must be initialized, a list of names that controls the ordering of things
        self.object_sizes = {} # must be initialized, a dictionary of name to length of the state
        self.object_num = dict() # must be initialized, a dictionary of name to number of instances of the object (max if not fixed)
        self.enumeration = dict() # the range of instance numbers
        self.indexes = dict() # the range of indexes in a flattened state


    def step(self, action):
        '''
        self.save_path is the path to which to save files, and self.itr is the iteration number to be used for saving.
        The format of saving is: folders contain the raw state, names are numbers, contain 2000 raw states each
        obj_dumps contains the factored state
        empty string for save_path means no saving state
        matches the API of OpenAI gym by taking in action (and optional params)
        returns
            state as dict: next raw_state (image or observation) next factor_state (dictionary of name of object to tuple of object bounding box and object property)
            reward: the true reward from the environment
            done flag: if an episode ends, done is True
            info: a dict with additional info
        '''
        pass

    def reset(self):
        '''
        matches the API of OpenAI gym, resetting the environment
        returns:
            state as dict: next raw_state, next factor_state (dict with corresponding keys)
        '''
        pass

    def render(self, mode='human'):
        '''
        matches the API of OpenAI gym, rendering the environment
        returns None for human mode
        '''

    def close(self):
        '''
        closes and performs cleanup
        '''

    def seed(self, seed):
        '''
        numpy should be the only source of randomness, but override if there are more
        '''
        np.random.seed(seed)


    def get_state(self):
        '''
        Takes in an action and returns:
            dictionary with keys:
                raw_state (dictionary of name of object to raw state)
                factor_state (dictionary of name of object to tuple of object bounding box and object property)
        '''
        pass

    def toString(self):
        '''
        creates a string form of the current extracted state of the environment (typically a dictionary of object name to object state)
        '''

    def get_itr(self):
        return self.itr

    def set_save(self, itr, save_dir, recycle, save_raw, all_dir=""):
        self.save_path=save_dir
        print(save_dir)
        self.itr = itr
        self.recycle = recycle
        self.all_dir = all_dir
        self.save_raw = save_raw
        try:
            os.makedirs(save_dir)
            os.makedirs(os.path.join(save_dir, "logs"))
        except OSError as e:
            print(e)
            pass
        object_dumps = open(os.path.join(self.save_path, "object_dumps.txt"), 'w') # create file if it does not exist
        action_dumps = open(os.path.join(self.save_path, "action_dumps.txt"), 'w')
        object_dumps.close()
        action_dumps.close()

    def write_objects(self, entity_state, frame): # TODO: put into parent class
        if self.recycle > 0:
            state_path = os.path.join(self.save_path, str((self.itr % self.recycle)//2000))
            count = self.itr % self.recycle
        else:
            state_path = os.path.join(self.save_path, str(self.itr//2000))
            count = self.itr
        try:
            os.makedirs(state_path)
        except OSError:
            pass

        if entity_state is not None:
            action_dumps = open(os.path.join(self.save_path, "action_dumps.txt"), 'a')
            action_dumps.write(action_toString(entity_state["Action"]) + "\t")
            action_dumps.close()
            object_dumps = open(os.path.join(self.save_path, "object_dumps.txt"), 'a')
            object_dumps.write(self.toString(entity_state) + "\n") # TODO: recycling does not stop object dumping
            object_dumps.close()
        if self.save_raw:
            imio.imsave(os.path.join(state_path, "state" + str(count % 2000) + ".png"), frame)

    def run(self, policy, iterations = 10000, render=False, save_path = "runs/", save_raw = True, duplicate_actions=1):
        self.set_save(0, save_path, -1, save_raw)
        try:
            os.makedirs(save_path)
        except OSError:
            pass
        for self.itr in range(iterations):
            action = policy.act(self)
            if action == -1: # signal to quit
                break
            self.step(action)

    def set_from_factored_state(self, factored_state):
        '''
        from the factored state, sets the environment.
        If the factored state is not complete, then this function does as good a reconstruction as possible
        '''
        pass
